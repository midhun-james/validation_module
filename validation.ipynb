{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midhun-james/validation_module/blob/main/validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install presidio_analyzer\n",
        "!pip install faker\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "EZDQup0oATuj",
        "outputId": "adfcec78-fc71-4e88-c881-38ac1cf3025e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.4)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio_analyzer-2.2.358 requests-file-2.1.0 tldextract-5.1.3\n",
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.1.0\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing - classify orgainization\n",
        "import re\n",
        "import os\n",
        "import gzip\n",
        "import time\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from collections import defaultdict\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "analyzer = AnalyzerEngine()\n",
        "fake=Faker()\n",
        "with open(\"test.json\", \"r\") as f:\n",
        "    fake_data_list = json.load(f)\n",
        "fake_data={}\n",
        "for data in fake_data_list:\n",
        "    for key,value in data.items():\n",
        "        fake_data[key]=set(value)\n",
        "\n",
        "entity_mapping={\n",
        "    'names':'PERSON',\n",
        "    'emails':'EMAIL_ADDRESS',\n",
        "    'phone':'PHONE_NUMBER',\n",
        "    'location':'LOCATION',\n",
        "    'credit':'CREDIT_CARD',\n",
        "    'url':'URL',\n",
        "    # 'country':'COUNTRY',\n",
        "    # 'company':\"ORG\",\n",
        "    'id':'ID',\n",
        "}\n",
        "\n",
        "mapping_file=\"mapping.json\"\n",
        "forward_mapping=defaultdict(dict)\n",
        "reverse_mapping=defaultdict(dict)\n",
        "\n",
        "if os.path.exists(mapping_file):\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping_data = json.load(f)\n",
        "        forward_mapping.update(mapping_data.get(\"forward_mapping\", {}))\n",
        "        reverse_mapping.update(mapping_data.get(\"reverse_mapping\", {}))\n",
        "def time_it(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_it\n",
        "def analyze_column(df):\n",
        "    entity_columns = {}  # Initialize as a dictionary\n",
        "\n",
        "    # Step 1: Use Presidio to analyze all columns\n",
        "    for col in df.columns:\n",
        "        if 'id' in col.lower():\n",
        "            entity_columns[col] = 'ID'\n",
        "        elif 'country' in col.lower():\n",
        "            entity_columns[col] = 'COUNTRY'\n",
        "        else:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            entity_counts = {}\n",
        "\n",
        "            for value in unique_values:\n",
        "                results = analyzer.analyze(text=value, language='en')\n",
        "                for result in results:\n",
        "                    entity_counts[result.entity_type] = entity_counts.get(result.entity_type, 0) + 1\n",
        "\n",
        "            if entity_counts:\n",
        "                predominant_entity = max(entity_counts, key=entity_counts.get)\n",
        "                      if predominant_entity==\"LOCATION\":\n",
        "                        org_count=0\n",
        "                        for value in unique_values:\n",
        "                          doc=nlp(value)\n",
        "                          for ent in doc.ents:\n",
        "                            if ent.label_==\"ORG\":\n",
        "                              org_count+=1\n",
        "                        if org_count>12:\n",
        "                          predominant_entity=\"ORG\"\n",
        "                entity_columns[col] = predominant_entity\n",
        "\n",
        "    # Step 2: Use SpaCy to analyze non-numeric and unclassified columns\n",
        "    for col in df.select_dtypes(exclude=['number']).columns:\n",
        "        if col not in entity_columns:\n",
        "            unique_values = df[col].dropna().astype(str).unique()[:25]\n",
        "            org_count = 0\n",
        "\n",
        "            for value in unique_values:\n",
        "                doc = nlp(value)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == 'ORG':\n",
        "                        org_count += 1\n",
        "\n",
        "            # If more than half of the sample values are ORG, classify as ORG\n",
        "            if org_count > 12:\n",
        "                entity_columns[col] = 'ORG'\n",
        "\n",
        "    return entity_columns\n",
        "\n",
        "def modify_fake_value(category, base_fake_value, counter):\n",
        "    if category == \"names\":\n",
        "        return f\"{base_fake_value} {string.ascii_uppercase[counter % 26]}.\"\n",
        "\n",
        "    elif category == \"emails\":\n",
        "        name, domain = base_fake_value.split(\"@\")\n",
        "        return f\"{name}{counter}@{domain}\"\n",
        "\n",
        "    elif category == \"location\":\n",
        "        return f\"{base_fake_value}, District {counter % 100_000_000 + 1}\"\n",
        "\n",
        "    elif category == \"url\":\n",
        "        return base_fake_value.replace(\"://\", f\"://sub{counter}.\", 1)\n",
        "\n",
        "    elif category == \"phone\":\n",
        "        return f\"{base_fake_value[:-2]}{counter % 100:02d}\"\n",
        "\n",
        "    elif category == \"company\":\n",
        "        return f\"{base_fake_value} Group {counter % 50}\"\n",
        "\n",
        "    elif category == \"credit\":\n",
        "        return f\"{base_fake_value[:-4]}{counter % 10000:04d}\"\n",
        "    else:\n",
        "        return f\"{base_fake_value}-{counter}\"\n",
        "\n",
        "\n",
        "\n",
        "def get_fake_value(category, original_value):\n",
        "    # Handle ID category separately for a unique format\n",
        "    if original_value in forward_mapping[category]:\n",
        "        return forward_mapping[category][original_value]\n",
        "    if category == 'id':\n",
        "        fake_value = fake.bothify(text='ID-############')\n",
        "    elif fake_data.get(category):\n",
        "        fake_value = fake_data[category].pop() if fake_data[category] else None\n",
        "    else:\n",
        "        # Reuse existing fake values or create a new unknown value\n",
        "        used_fake=list(forward_mapping[category].values())\n",
        "        if used_fake:\n",
        "          base_fake_value=random.choice(used_fake)\n",
        "          counter=len(used_fake)\n",
        "          fake_value=modify_fake_value(category,base_fake_value,counter)\n",
        "\n",
        "    # Save mappings\n",
        "    forward_mapping[category][original_value] = fake_value\n",
        "    reverse_mapping[category][fake_value] = original_value\n",
        "\n",
        "    return fake_value\n",
        "\n",
        "@time_it\n",
        "def mask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "        if matching_keys:\n",
        "            df[col] = df[col].astype(str).apply(lambda x: get_fake_value(matching_keys[0], str(x)) if x else str(x))\n",
        "    return df\n",
        "def restore_original_value(category, fake_value):\n",
        "    return reverse_mapping[category].get(fake_value, fake_value)\n",
        "\n",
        "@time_it\n",
        "def unmask_dataframe(df):\n",
        "    for col, entity in entity_columns.items():\n",
        "        matching_keys = [key for key, value in entity_mapping.items() if value == entity]\n",
        "\n",
        "        if matching_keys:\n",
        "            category = matching_keys[0]\n",
        "            df[col] = df[col].astype(str).apply(lambda x: restore_original_value(category, str(x)) if x else str(x))\n",
        "\n",
        "    return df\n",
        "def compare_files(original_file, restored_file):\n",
        "    \"\"\"Check if the original and restored files are identical.\"\"\"\n",
        "    file_ext = os.path.splitext(original_file)[-1].lower()\n",
        "    original_df = pd.read_excel(original_file) if file_ext == \".xlsx\" else pd.read_csv(original_file)\n",
        "    restored_df = pd.read_excel(restored_file) if file_ext == \".xlsx\" else pd.read_csv(restored_file)\n",
        "\n",
        "    is_identical = original_df.equals(restored_df)\n",
        "    print(f\"📊 Are files identical? {'✅ Yes' if is_identical else '❌ No'}\")\n",
        "    if not is_identical:\n",
        "        print(\"⚠️ The restored file does not match the original. There may be an issue with the mapping.\")\n",
        "\n",
        "    return is_identical\n",
        "def de_anonymize_paragraph(text):\n",
        "  for category,mapping in reverse_mapping.items():\n",
        "    for fake_value,original_value in mapping.items():\n",
        "      if fake_value in text:\n",
        "        text=text.replace(fake_value,original_value)\n",
        "  return text\n",
        "def save_mapping():\n",
        "    mapping_data={\n",
        "        \"forward_mapping\":forward_mapping,\n",
        "        \"reverse_mapping\":reverse_mapping\n",
        "    }\n",
        "    with open(mapping_file, \"w\") as f:\n",
        "        json.dump(mapping_data, f, indent=4)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    input_file=\"test.csv\"\n",
        "    file_ext=os.path.splitext(input_file)[-1].lower()\n",
        "\n",
        "    df = pd.read_excel(input_file, dtype=str) if file_ext == \".xlsx\" else pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "    entity_columns=analyze_column(df)\n",
        "    print(entity_columns)\n",
        "\n",
        "    anonymized_df=mask_dataframe(df)\n",
        "    output_file=\"anonymized.xlsx\" if file_ext==\".xlsx\" else \"anonymized.csv\"\n",
        "    anonymized_df.to_excel(output_file,index=False) if file_ext==\".xlsx\" else anonymized_df.to_csv(output_file,index=False)\n",
        "    print(f\"✅ Anonymized data saved as {output_file}\")\n",
        "\n",
        "    save_mapping()\n",
        "    restored_df=unmask_dataframe(pd.read_excel(output_file) if file_ext==\".xlsx\" else pd.read_csv(output_file))\n",
        "    restored_file=\"restored.xlsx\" if file_ext==\".xlsx\" else \"restored.csv\"\n",
        "    restored_df.to_excel(restored_file,index=False) if file_ext==\".xlsx\" else restored_df.to_csv(restored_file,index=False)\n",
        "    print(f\"✅ Restored data saved as {restored_file}\")\n",
        "    compare_files(input_file, restored_file)"
      ],
      "metadata": {
        "id": "mbRkyYDvANGa",
        "outputId": "482bd25b-de14-49e4-8779-b961119e6c51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    input_file=\"test.csv\"\n",
        "    file_ext=os.path.splitext(input_file)[-1].lower()\n",
        "\n",
        "    df = pd.read_excel(input_file, dtype=str) if file_ext == \".xlsx\" else pd.read_csv(input_file, dtype=str, low_memory=False)\n",
        "    entity_columns=analyze_column(df)\n",
        "    print(entity_columns)\n",
        "\n",
        "    anonymized_df=mask_dataframe(df)\n",
        "    output_file=\"anonymized.xlsx\" if file_ext==\".xlsx\" else \"anonymized.csv\"\n",
        "    anonymized_df.to_excel(output_file,index=False) if file_ext==\".xlsx\" else anonymized_df.to_csv(output_file,index=False)\n",
        "    print(f\"✅ Anonymized data saved as {output_file}\")\n",
        "\n",
        "    save_mapping()\n",
        "    restored_df=unmask_dataframe(pd.read_excel(output_file) if file_ext==\".xlsx\" else pd.read_csv(output_file))\n",
        "    restored_file=\"restored.xlsx\" if file_ext==\".xlsx\" else \"restored.csv\"\n",
        "    restored_df.to_excel(restored_file,index=False) if file_ext==\".xlsx\" else restored_df.to_csv(restored_file,index=False)\n",
        "    print(f\"✅ Restored data saved as {restored_file}\")\n",
        "    compare_files(input_file, restored_file)"
      ],
      "metadata": {
        "id": "kFg-6XmHAP4d",
        "outputId": "cda75767-bfa8-44d0-b283-50e356d4372d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n",
            "2\n",
            "0\n",
            "\n",
            "⏳ Execution time analyze_column: 4.885260 seconds\n",
            "{'id': 'ID', 'country': 'COUNTRY', 'name': 'ORG', 'domain': 'URL', 'size range': 'DATE_TIME', 'locality': 'LOCATION', 'linkedin url': 'URL', 'current employee estimate': 'US_DRIVER_LICENSE', 'total employee estimate': 'US_DRIVER_LICENSE'}\n",
            "\n",
            "⏳ Execution time mask_dataframe: 0.003151 seconds\n",
            "✅ Anonymized data saved as anonymized.csv\n",
            "\n",
            "⏳ Execution time unmask_dataframe: 0.001795 seconds\n",
            "✅ Restored data saved as restored.csv\n",
            "📊 Are files identical? ❌ No\n",
            "⚠️ The restored file does not match the original. There may be an issue with the mapping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2EroohMlA8U4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}